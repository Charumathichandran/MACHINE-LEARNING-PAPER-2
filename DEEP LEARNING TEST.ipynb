{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0e9994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>13867</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>Abortion</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Abortion\\nWomen's Issues (not abortion though)</td>\n",
       "      <td>RT @cappy_yarbrough: Love to see men who will ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:29:43 -0700</td>\n",
       "      <td>629690895479250944</td>\n",
       "      <td>Como</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>13868</td>\n",
       "      <td>Mike Huckabee</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>Mike Huckabee</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @georgehenryw: Who thought Huckabee exceede...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:25:02 -0700</td>\n",
       "      <td>629689719056568320</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>13869</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Positive\\nNeutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Lrihendry: #TedCruz As President, I will a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 07:19:18 -0700</td>\n",
       "      <td>629658075784282112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>13870</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Women's Issues (not abortion though)</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Women's Issues (not abortion though)</td>\n",
       "      <td>RT @JRehling: #GOPDebate Donald Trump says tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:04 -0700</td>\n",
       "      <td>629697023663546368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>13871</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>65</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Lrihendry: #TedCruz headed into the Presid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-06 18:22:27 -0700</td>\n",
       "      <td>629462573641920512</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13871 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id               candidate  candidate_confidence relevant_yn  \\\n",
       "0          1  No candidate mentioned                1.0000         yes   \n",
       "1          2            Scott Walker                1.0000         yes   \n",
       "2          3  No candidate mentioned                1.0000         yes   \n",
       "3          4  No candidate mentioned                1.0000         yes   \n",
       "4          5            Donald Trump                1.0000         yes   \n",
       "...      ...                     ...                   ...         ...   \n",
       "13866  13867  No candidate mentioned                1.0000         yes   \n",
       "13867  13868           Mike Huckabee                0.9611         yes   \n",
       "13868  13869                Ted Cruz                1.0000         yes   \n",
       "13869  13870            Donald Trump                1.0000         yes   \n",
       "13870  13871                Ted Cruz                0.9242         yes   \n",
       "\n",
       "       relevant_yn_confidence sentiment  sentiment_confidence  \\\n",
       "0                      1.0000   Neutral                0.6578   \n",
       "1                      1.0000  Positive                0.6333   \n",
       "2                      1.0000   Neutral                0.6629   \n",
       "3                      1.0000  Positive                1.0000   \n",
       "4                      1.0000  Positive                0.7045   \n",
       "...                       ...       ...                   ...   \n",
       "13866                  1.0000  Negative                0.7991   \n",
       "13867                  1.0000  Positive                0.7302   \n",
       "13868                  1.0000  Positive                0.8051   \n",
       "13869                  1.0000  Negative                1.0000   \n",
       "13870                  0.9614  Positive                0.9614   \n",
       "\n",
       "                             subject_matter  subject_matter_confidence  \\\n",
       "0                         None of the above                     1.0000   \n",
       "1                         None of the above                     1.0000   \n",
       "2                         None of the above                     0.6629   \n",
       "3                         None of the above                     0.7039   \n",
       "4                         None of the above                     1.0000   \n",
       "...                                     ...                        ...   \n",
       "13866                              Abortion                     0.6014   \n",
       "13867                     None of the above                     0.9229   \n",
       "13868                     None of the above                     0.9647   \n",
       "13869  Women's Issues (not abortion though)                     0.9202   \n",
       "13870                     None of the above                     0.9242   \n",
       "\n",
       "               candidate_gold  ... relevant_yn_gold retweet_count  \\\n",
       "0                         NaN  ...              NaN             5   \n",
       "1                         NaN  ...              NaN            26   \n",
       "2                         NaN  ...              NaN            27   \n",
       "3                         NaN  ...              NaN           138   \n",
       "4                         NaN  ...              NaN           156   \n",
       "...                       ...  ...              ...           ...   \n",
       "13866  No candidate mentioned  ...              yes             7   \n",
       "13867           Mike Huckabee  ...              yes             1   \n",
       "13868                Ted Cruz  ...              yes            67   \n",
       "13869            Donald Trump  ...              yes           149   \n",
       "13870                Ted Cruz  ...              yes            65   \n",
       "\n",
       "          sentiment_gold                             subject_matter_gold  \\\n",
       "0                    NaN                                             NaN   \n",
       "1                    NaN                                             NaN   \n",
       "2                    NaN                                             NaN   \n",
       "3                    NaN                                             NaN   \n",
       "4                    NaN                                             NaN   \n",
       "...                  ...                                             ...   \n",
       "13866           Negative  Abortion\\nWomen's Issues (not abortion though)   \n",
       "13867                NaN                                             NaN   \n",
       "13868  Positive\\nNeutral                                             NaN   \n",
       "13869                NaN            Women's Issues (not abortion though)   \n",
       "13870           Positive                                             NaN   \n",
       "\n",
       "                                                    text tweet_coord  \\\n",
       "0      RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1      RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2      RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3      RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "...                                                  ...         ...   \n",
       "13866  RT @cappy_yarbrough: Love to see men who will ...         NaN   \n",
       "13867  RT @georgehenryw: Who thought Huckabee exceede...         NaN   \n",
       "13868  RT @Lrihendry: #TedCruz As President, I will a...         NaN   \n",
       "13869  RT @JRehling: #GOPDebate Donald Trump says tha...         NaN   \n",
       "13870  RT @Lrihendry: #TedCruz headed into the Presid...         NaN   \n",
       "\n",
       "                   tweet_created            tweet_id   tweet_location  \\\n",
       "0      2015-08-07 09:54:46 -0700  629697200650592256              NaN   \n",
       "1      2015-08-07 09:54:46 -0700  629697199560069120              NaN   \n",
       "2      2015-08-07 09:54:46 -0700  629697199312482304              NaN   \n",
       "3      2015-08-07 09:54:45 -0700  629697197118861312            Texas   \n",
       "4      2015-08-07 09:54:45 -0700  629697196967903232              NaN   \n",
       "...                          ...                 ...              ...   \n",
       "13866  2015-08-07 09:29:43 -0700  629690895479250944             Como   \n",
       "13867  2015-08-07 09:25:02 -0700  629689719056568320              USA   \n",
       "13868  2015-08-07 07:19:18 -0700  629658075784282112              NaN   \n",
       "13869  2015-08-07 09:54:04 -0700  629697023663546368              NaN   \n",
       "13870  2015-08-06 18:22:27 -0700  629462573641920512  San Antonio, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "0                           Quito  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3      Central Time (US & Canada)  \n",
       "4                         Arizona  \n",
       "...                           ...  \n",
       "13866                         NaN  \n",
       "13867                         NaN  \n",
       "13868                         NaN  \n",
       "13869                         NaN  \n",
       "13870  Central Time (US & Canada)  \n",
       "\n",
       "[13871 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x=pd.read_csv(\"C:/Users/charumathi/Downloads/Paper2/Sentiment.csv\")\n",
    "df=pd.DataFrame(x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1d469f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f87431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"text\",\"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "090c6b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ff4cb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ebe6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3b963",
   "metadata": {},
   "source": [
    "### Q1. Print the total number of positive and negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86a27b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positive Sentiments 1709\n",
      "Total Negative Sentiments 6129\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Positive Sentiments\",len(df[df['sentiment']=='Positive']))\n",
    "print(\"Total Negative Sentiments\",len(df[df['sentiment']=='Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020aa40b",
   "metadata": {},
   "source": [
    "### Q2. Build a sequential LSTM model to predict positive and negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a42c7df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\charumathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66dc09d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he is a great leader.\n"
     ]
    }
   ],
   "source": [
    "lower=text\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c23ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'is', 'a', 'great', 'leader.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dc52c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'is', 'a', 'great', 'leader', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token=word_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecdfac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'He': 1, 'is': 1, 'a': 1, 'great': 1, 'leader': 1, '.': 1})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist=FreqDist(token)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7279f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['He', 'is']),\n",
       " WordList(['is', 'a']),\n",
       " WordList(['a', 'great']),\n",
       " WordList(['great', 'leader'])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "from textblob import TextBlob\n",
    "TextBlob(text).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0440c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb99b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'a', 'great', 'leader', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\charumathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "a=set(stopwords.words('english'))\n",
    "x=word_tokenize(text.lower())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90aab979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c6e9474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\charumathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15d388ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch full #GOPdebate ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina trending -- ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On first day I r...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked happy I heard goin...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845</th>\n",
       "      <td>RT @the818: Let's play \"how fast distance Trum...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13847</th>\n",
       "      <td>RT @mjtbaum: GOD making appearance #GOPDebate?...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13857</th>\n",
       "      <td>This I watch Fox News, they're asshole #GopDeb...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13859</th>\n",
       "      <td>Best line #GOPDebate \"Immigration without assi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>RT @georgehenryw: Who thought Huckabee exceede...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7838 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "1      RT @ScottWalker: Didn't catch full #GOPdebate ...  Positive\n",
       "3      RT @RobGeorge: That Carly Fiorina trending -- ...  Positive\n",
       "4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5      RT @GregAbbott_TX: @TedCruz: \"On first day I r...  Positive\n",
       "6      RT @warriorwoman91: I liked happy I heard goin...  Negative\n",
       "...                                                  ...       ...\n",
       "13845  RT @the818: Let's play \"how fast distance Trum...  Negative\n",
       "13847  RT @mjtbaum: GOD making appearance #GOPDebate?...  Positive\n",
       "13857  This I watch Fox News, they're asshole #GopDeb...  Negative\n",
       "13859  Best line #GOPDebate \"Immigration without assi...  Positive\n",
       "13867  RT @georgehenryw: Who thought Huckabee exceede...  Positive\n",
       "\n",
       "[7838 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "df['text'] = df.text.apply(lemmatize_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b76b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of each text :  12.240877774942588\n",
      "Percentage of text with positive sentiment is 0.0%\n",
      "Percentage of text with negative sentiment is 100.0%\n"
     ]
    }
   ],
   "source": [
    "s = 0.0\n",
    "for i in df['text']:\n",
    "    word_list = i.split()\n",
    "    s = s + len(word_list)\n",
    "print(\"Average length of each text : \",s/df.shape[0])\n",
    "pos = 0\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i]['sentiment'] == 'positive':\n",
    "        pos = pos + 1\n",
    "neg = df.shape[0]-pos\n",
    "print(\"Percentage of text with positive sentiment is \"+str(pos/df.shape[0]*100)+\"%\")\n",
    "print(\"Percentage of text with negative sentiment is \"+str(neg/df.shape[0]*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e53857",
   "metadata": {},
   "source": [
    "### Q3.Based on the model, check the sentiment for the following two sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0fb11",
   "metadata": {},
   "source": [
    "### a. 'He is a great leader.'b. 'He is a terrible leader.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61afcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(tweet)from keras .preprocessing.text import Tokenizer\n",
    "sentence = ['He is a great leader','He is a terrible leader.' ]\n",
    "# convert to a sequence\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "# pad the sequence\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "prediction = model.predict(padded)\n",
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "for i in range(len(sentence)):\n",
    "    print(sentence[i])\n",
    "    if pred_labels[i] == 1:\n",
    "        s = 'Positive'\n",
    "    else:\n",
    "        s = 'Negative'\n",
    "    print(\"Predicted sentiment : \",s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
